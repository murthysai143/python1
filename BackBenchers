import numpy as np # linear algebra
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.simplefilter('ignore')
train=pd.read_csv("C:/Users/MURTHY SAI/Downloads/test.csv")
test=pd.read_csv("C:/Users/MURTHY SAI/Downloads/test.csv")
train.head()
test.head()
train.info()
test.info()
train.size
test.size
df = pd.concat([train, test], axis=0)
df.head()
df.shape
df.isna().sum()
plt.figure(figsize=(10, 6))
sns.histplot(df['price'], kde=True)
plt.title('Distribution of House Prices')
plt.xlabel('Price')
plt.ylabel('Frequency')
plt.show()
plt.figure(figsize=(10, 6))
sns.boxplot(x='beds', y='price', data=df)
plt.title('House Prices by Number of Bedrooms')
plt.xlabel('Number of Bedrooms')
plt.ylabel('Price')
plt.show()
plt.figure(figsize=(10, 6))
sns.scatterplot(x='size', y='price', data=df)
plt.title('House Prices vs Size of Property')
plt.xlabel('Size')
plt.ylabel('Price')
plt.show()
df.dropna(inplace=True)
df.isnull().sum()
df.columns
x= df.drop('price', axis = 1)
y=df['price']
print("Columns in dataset:", df.columns)
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import numpy as np

# Data Preprocessing
# Convert lot size from acres to sqft where necessary
df.loc[df['lot_size_units'] == 'acre', 'lot_size'] *= 43560  # 1 acre = 43560 sqft

# Drop unnecessary columns
df = df.drop(columns=['size_units', 'lot_size_units'])

# Handle missing values (fill missing lot sizes with median)
df['lot_size'].fillna(df['lot_size'].median(), inplace=True)

# Define features and target variable
X = df.drop(columns=['price'])
y = df['price']

# Evaluate the model
# Split the dataset
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train Random Forest model
rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

# Make predictions
y_pred = rf_model.predict(X_test)

mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, y_pred)

mae, rmse, r2
